\documentclass{article}
\usepackage{amsmath}
\title{Andrew Ng Stanford, Machine Learning Solution Work}
\author{By Wesley Guergah}
\date{April 2018}

\begin{document}

\maketitle

\section{Assignment 1-Linear Regression and Gradient Descent}
\\
The program in assignment 1 utilizes Gradient Descent to create an optimized prediction function for the total profit of a food truck in a city. I create the best fit for the past data using the gradient algorithm. The algorithm is  generalized to the multivariate case, where instead of two variables (population,profit), I may include more (population,profit,median income, population density, ect.)
\\
\\
B) \textbf {Matlab Code to Plot Data}
\\
\newline
plotdata()
\\
\\
First, we load the data onto Matlab from a file:
\\
\newline 
data=load('ex1data1.txt');
\newline \\
x=data(:,1); \\
\newline
y=data(:,2);\\
\newline
The data(:,1), data(:,2) commands take the first and second columns of the data and stores them as individual columns of data.
\newline
\\
We plot the data points and label them with "x"'s, as well as labelling the axes:
\\
\\
plot(x,y,'rx', 'MarkerSize',10);
\newline
\\
xlabel('Population');
\newline
\\
ylabel('Profits');
\newline
\\
C) \textbf{Code for computing the cost function}
\\
\newline
The cost function is given as:
\newline
\newline
J($\theta$)=$\frac{1}{2m}$ $\sum_{n=1}^{m} (h_{\theta}(x^{i})-y^{i})^2$;
\newline
\newline
We would like to compute the cost function using a for loop for a given set of data.
Now, the pair $(x^{i},y^{i}) $ is the $i^{th}$ training example, and, $h_{\theta}(x^i)=\theta_0-\theta_1x_1$ is the prediction function.
\newline
Note, we are working with vectors, where $x^i = \Vec{x}= [x_0,x_1,...,x_n]$ to emphasize that $x^i$ is a vector.
\\
\\ Note, we can write the prediction function $h_{\theta}(x)$ using vector notation as:  $h_{\theta}(x)=\theta^Tx$ where 
$\theta^T$ denotes theta transpose. \\
\newline
First we initialize the sum, and then we loop through the total number of training examples, adding the cost of each to the total sum:
\\
\newline
J=0;
\\
for i=1:m 
\\
$J=J+(X(i,:)*theta-y(i))^2$;
\newline
end
\newline
\\
We then sum all the individual values contained in the cost vector:
\newline
\\
J = sum(J);
\newline
\\
and lastly divide by 2m:
\newline
\\
J=J/(2*m);
\\
\\
D) \textbf{Gradient Descent Algorithm}
\\
\\
asum = zeros(length(theta));
\newline
\\
for j = 1:length(theta)\\
for i = 1:m\\
asum(j) = asum(j)+(X(i,:)*theta-y(i))*X(i,j);
\\
end
\\
end
\\
for k=1:length(theta)
\\
theta(k)=theta(k)-(alpha/m)*asum(k);
\\
end
\\
NOTE: This algorithm is generalized to handle more than the one-dimensional case, therefore, it is used again in the multivariate problem.
\\


\section{Multivariate Linear Regression}

\\(A)\textbf{Normalization}
\\
\\
First, we Normalize the features of our data set X. We do this using the mean and standard deviation functions built into MATLAB.\\
\\
for i=1:length(mu)
\\
\\
mu(i)=mean(X(:,i));
\\
end
\\
\\
for i=1:length(sigma)
\\
sigma(i)=std(X(:,i));
\\
end
\\
\\
for i=1:size(X,2)
\\
X$_$norm(:,i)=(X(:,i)-mu(i))/(sigma(i));
\\
end
\\
\\
(B) \textbf{Cost Computation}
\\
\\
for i=1:m
\\
J=J+(X(i,:)*theta-y(i)).$^2$;
\\
end
\\
J=sum(J);
\\
J=J/(2*m);
\\
\\
\\
(C) \textbf{Multivariate Gradient Descent}
\\
\\
asum=zeros(length(theta));\\
for j=1:length(theta)\\
for i=1:m\\
\\
asum(j)=asum(j)+(X(i,:)*theta-y(i))*X(i,j);
\\
end
\\
end
\\
\\
for k=1:length(theta)
\\
theta(k)=theta(k)-(alpha/m)*asum(k);
\\
end
\\
We update the price function after completing the gradient descent code, and note that we also normalize the values before calculation:
\\
\\
$price = [1,(1650-mu(1))/sigma(1),(3-mu(2))/sigma(2)]*theta$;
\\
\\
(D) 
\textbf{Implementation using Normal Equations}
\\
\\ 
The normal equation uses a closed form solution to optimize the best fit.
\\
The solution is given as:
\\
\\
$\theta=(X^TX)^{-1}X^T\Vec{y}$
\\
\\
In matlab:
\\
\\
theta=(X'*X)$^(-1)$*X'*y;
\\
\\
NOTE: After changing the learning rate alpha to .1, and the number of iterations to 1,000 the result of the normal equation and gradient descent is identical. 
\\

\section{Assignment 2-Logistic Regression }
\\
This program uses Logistic Regression to determine weather a student will be admitted into university or not, based on exam scores. This problem also utilizes gradient descent to minimize the cost function associated with some hypothesis function. This assignment involves a typical classification problem and discrete valued data sets.
\\
\\
The plotting commands are provided in the exercise, and the documentation can be read online.
\\
\\
\newline
(A) \textbf{Sigmoid Function}
\newline
\\
We define the sigmoid or Logistic function in matlab. The sigmoid function is useful for logistic regression problems, since we will have the property that
\\
$0\leq h_{\theta} (x)<1$
\\
\\
The sigmoid function is defined as $g(z)=(1+e^{-z})^{-1}$
\\
The matlab code is as follows:
\\
\\
function g = sigmoid(z)
\\
\newline
g=zeros(size(z));
\\
\newline
for i=1:numel(z)
\newline
\\
$g(i)=(1+exp(-z(i)))^{-1}$;
\newline
end
\newline
\\
(B)\textbf{Cost Function and Gradient computation for Logistic Regression}
\\
\\
Note, we can not use the same cost function used in linear regression because it will cause the output to have many local minima. Instead, we alter the cost function to provide a convex output.
\\
\\
The cost function for gradient descent is given as:
\\
\\
$J(\theta)=\frac{1}{m}\sum_{i=1}^{m}-y^{i}log(h_{\theta}(x^i))-(1-y^i)log(1-h_{\theta}(x^i))$
\newline
The following matlab code computes the cost of a particular choice of $\theta$, along with the gradient vector:\\
\\
% Code for cost computation:
\\
for i=1:m
\\
\\
h=sigmoid(dot(X(i,:),theta));
\\
\\
J=J+((-1)*y(i)*log(h)-(1-y(i))*log(1-h));
\\
end
\\
\\
% Code for gradient computation:

for j=1:length(grad)
\\
\\
for i=1:m
\\
\\
grad(j)= grad(j)+(sigmoid((X(i,:)*theta))-y(i))*X(i,j);
\\
\\
end
end
\\
J=J/m;
grad=grad/m;
\\
\\
C) \textbf{Prediction Accuracy}
\\
We make can create an array of prediction results and compare them to the training set to see how well the model performs on known data:
\\
\\
for i=1:m
\\
if (sigmoid(X(i,:)*theta)$>=$.5)
\\
\\
p(i)=1;
\\
else
\\
\\
p(i)=0;
\\
end
\\
\\
D) \textbf{Regularized logistic regression}
\\
Code for computing the cost in the regularized case:
\\
\\
for i=1:m
\newline
h=sigmoid(dot(X(i,:),theta));
\newline
J=J+((-1)*y(i)*log(h)-(1-y(i))*log(1-h);
\\
\newline
end
\newline
thetaFactor=0;
\newline
for j=2:length(X(1,:))
\newline
\\
thetaFactor = thetaFactor+(theta(j))$^$2;
\newline
end
\\
Code for computing the gradient vector:
\newline
for j=1:length(grad)
\\
for i=1:m
\\
\\
h=sigmoid(dot(X(i,:),theta));
\newline
grad(j)= grad(j)+(h-y(i))*X(i,j);
\newline
end
end
\newline
grad=grad/m;
\newline
for i=2:length(grad)
\\
\\
grad(i)=grad(i)+(theta(i)*lambda)/m;
\newline
end
\\
J=(J/m)+(thetaFactor*lambda)/(2*m);
\newline
end
\\
Note, in the optional exercises you can
experiment with different values of lambda to see the effect on under fitting or over fitting the data.

\maketitle
\section{Assignment 3-Neural Networks}
(A)\textbf{Regularized/Vectorized Cost Function}
\\
\\
x=sigmoid(X*theta); 
\newline
\\
J= (-y'*log(x)-(1-y')*log(1-x))/m;
\\
\\
$J = J+sum((theta(2:end)).^2)*lambda/(2*m)$;
\\
\\ 
(B) \textbf{Gradient Function}
\\
\\
grad = (1/m)*X'*(x-y);
\\
temp = theta; \\
temp(1) = 0;\\
\\
temp = temp*(lambda/m);\\
\\
grad = grad + temp; \newline
\newline
(C) \textbf{One Vs. All Classification} \newline
\\
for c = 1:num\_labels
\newline
initial\_theta = zeros(n + 1, 1);
\\
options = optimset('GradObj', 'on', 'MaxIter', 50);
\\
theta = ...
fmincg (@(t)(lrCostFunction(t, X, (y == c), lambda)), ...initial\_theta, options);
\\
\\
[all\_theta(c,:)] = theta';    
\newline
end
\newline
(D) \textbf{One Vs. All Predictions}
\newline
 pro = X * all$_$theta';
 \\
 \\
 m * num$_$labels
 \\
 kind = max(pro, [], 2);
 for i = 1: m
p(i) = find(pro(i,:) == kind(i));
end

\section{Programming Assignment 4}
\\
\\
In the cost function code, we loop through each training example, first calculating the first layer weights (flw) by multiplying the ith training example $X(i,:)$ by the Theta1 matrix. After adding the bias node, we calculate second layer weights (slw) by multiplying the first layer weights with the Theta2 matrix. Lastly, the prediction is given by sigmoid(slw). Then, we increment the cost variables using the same formula used in the logistic regression case, except here it is generalized to handle vectors. Note, we have to convert the y vector to a matrix containg appropriate labels.
\\
\\
Initialize the cost variable:\\
J = 0;
\\
Add a column of ones to the X matrix:
\\
X = [ones(size(X(:,1))) X];
\\
\\
Converting the labels for the digits into their corresponding vectors is achieved using Matlab's REPMAT command:
\\
\\
Y = repmat(y(:),1,num$_$labels) == repmat(1:num$_$labels,m,1);
\\
\\
Code for computing the cost:
\\
for i=1:m
\\
flw = sigmoid(Theta1*X(i,:)');
\\
flw = [1;flw];
\\
slw = Theta2*flw;
\\
prediction = sigmoid(slw);
\\
J=J+(-1*Y(i,:)*log(prediction)-(1-Y(i,:))*log(1-prediction));
\\
end
\\
\\
J=J/m;
\\
We then regularize the cost by the following method:
\\
\\
%Sum terms for regularization:
thet1 = Theta1(:,2:end);
\\
thet2 = Theta2(:,2:end);
\\
thet1=thet1.$^$2;
\\
thet2=thet2.$^$2;
\\
s1=sum(sum(thet1));
\\
s2=sum(sum(thet2));
\\
s=(s1+s2)*(lambda/(2*m));
\\
J=J+s;
\\
Now, Backpropogation algorithm:
\\
Theta1$_$grad = zeros(size(Theta1));
\\
Theta2$_$grad = zeros(size(Theta2));
\\
for t=1:
\\
a$_$1=X(t,:);   % a_1 is 1 X 401, Theta1 is 25 X 401;
\\
z$_$1=[Theta1*a$_$1'];  % 25 X 1
\\
a$_$2=[1;sigmoid(z$_$1)]; % 26 X 1
\\
z$_$2=Theta2*a$_$2;
\\
a$_$3=sigmoid(z$_$2);  % 10 X 1
\\
delta$_$3=a$_$3-Y(t,:)'; % 10 X 1
\\
delta$_$2=Theta2'*delta$_$3.*sigmoidGradient([1;z$_$1]); % 26 X 10 times 
\\
\\
delta$_$2=delta$_$2(2:end);
\\
Theta1$_$grad = Theta1$_$grad+delta$_$2*a$_$1;
\\
\\
Theta2$_$grad =Theta2$_$grad+delta$_$3*a$_$2';
\\
end
\\
\\
Theta1$_$grad=Theta1$_$grad/m;
\\
Theta2$_$grad=Theta2$_$grad/m;
\\
Finally, the code to regularize back prop:
\\
\\
Theta1$_$grad=Theta1$_$grad+(lambda/m)*Theta1;
\\
Theta2$_$grad=Theta2$_$grad+(lambda/m)*Theta2;
\\
Theta1$_$grad(:,1) = Theta1$_$grad(:,1)-(lambda/m)*Theta1(:,1);
\\
Theta2$_$grad(:,1) = Theta2$_$grad(:,1)-(lambda/m)*Theta2(:,1);
\\
\section{Programming Exercise 5}
\\
This exercise starts with a learning algorithm that uses change in water level x, and water flowing out of the dam, y, to create a learning algorithm. We use techniques to address inherent bias and variance in the algorithm. This may involve changing $\lambda$, the regularization parameter, or manipulating $m$, the number of training examples, as well as splitting the data into segments, $Data_{Train}$, $Data_{CV}$, and finally, $Data_{Test}$.
\\
\\
We initialize the cost, vectorize the cost computation, and then add the regularization terms:
\\
\\
J=0
\\
J=(X*theta-y).$^$2;
\\
J=(sum(J))/(2*m);
\\
J=J+sum((theta(2:end)).$^$ 2)*lambda/(2*m);
\\
% Vectorize the gradient calculation:
\\
grad=((X*theta-y)'*X)';
\\
grad = grad/m;
\\
regTerms=zeros(size(theta));
\\
regTerms=theta*lambda/m;
\\
regTerms(1)=0;
\\
\\
grad=grad+regTerms;
\\
end
\\
We then transform the matrix X into a matrix XPoly, in order to increase the number of features
\\
\\
for i=1:p
\\
\\
XPoly(:,i)=X.$^i$;
\\
\\
We then implement code that compares the error in the validation set and the training set. Note, in the training set, we train X with an increasing number of examples, from 1 to m. 
\\
end
\\
\\
for i=1:m
\\
theta=trainLinearReg(X(1:i,:), y(1:i),lambda);
\\
error_train(i)=linearRegCostFunction(X(1:i,:),y(1:i),theta,0);
\\
error_val(i)=linearRegCostFunction(Xval,yval,theta,0);
\\
end

Lastly, we look at how the lambda parameter effects the training and validation data. 

for i = 1:length(lambda_vec)
\\  
lambda = lambda_vec(i);
\\
theta=trainLinearReg(X, y,lambda);
\\
error_train(i)=linearRegCostFunction(X,y,theta,0);
\\
error_val(i)=linearRegCostFunction(Xval,yval,theta,0);
\\
end

\section{Programming Exercise 6}
\\
In the first half of this exercise, we use support vector machines (SVMs) with various example 2D datasets. Experimenting with these datasets gives an intuition of how SVMs work and how to use a Gaussian kernel with SVMs. Then we use support vector machines to build a spam classifier.
\\
\textbff{Writing a Gaussian kernel}
\\
The matlab code to return the Gaussian kernel is as follows:
\\
$sim = (x1-x2).^2$;
\\
$sim = sum(sim)/(2*sigma^2)$;
\\
$sim=exp((-1)*sim)$;
\\
The matlab code to optimize the sigma and C parameters is as follows:
\\
params = [.01 .03 .1 .3 1 3 10 30];
\\
model= svmTrain(X, y, C, @(x1, x2)
\\
gaussianKernel(x1, x2, sigma));
\\
predict=svmPredict(model,Xval);
\\
minError = mean(double(predict ~= yval));
\\
minC=Inf;
\\
minSigma=Inf;
\\
for i=1:length(params)
\\
for j=1:length(params)
\\
        currentC=params(i);
        \\
        currentSigma=params(j);
        \\
        model= svmTrain(X, y, currentC, @(x1, x2) gaussianKernel(x1, x2, currentSigma));
        \\
        predict=svmPredict(model, Xval);
        \\
        error = mean(double(predict ~= yval));
        \\
if (error<minError)
\\
    minError=error;
    \\
    minC=currentC;
    \\
    minSigma=currentSigma;
    \\
end
\\
end
\\
end
\\
C=minC;
\\
sigma=minSigma;
\\
\\
Next, the email processing code:
\\
for i=1:length(vocabList)
\\
if (strcmp(vocabList(i),str) == 1)  % A match found in the vocab List
\\
% Add the match to the wordindices vector
\\
wordindices = [wordindices; i]; 
\\
end
\\
end
\\
Now, we create a feature vector for a given email using the following :
\\
\\
for i = 1 : length(wordindices)
\\
    x(wordindices(i)) = 1;
    \\
end
\\
\section{Exercise 7}
\\
\\
We implement the K-means clustering algorithm and apply it to compress an image. In the second part, we use principal component analysis to find a low-dimensional representation of face images.
\\ 
\\ We use an iterative method to find the centroid closest to the ith training example. The norm function in matlab gives the euclidean distance.
\\
for i=1:length(idx)
\\
    min=Inf;
    \\
    for k=1:K
    \\
        currentMin = norm(X(i,:)-centroids(k,:));
        \\
        if (currentMin<=min)
        \\
        min = currentMin;
        \\
        idx(i)=k;
        \\
        end
        \\
end 
\\
end
\\
\\
In this part, we use another iterative method to rearrange the K clusters to the "center of mass" of the training examples. We find the coordinated of the center of mass for the kth centroid by averaging over all of the training labelled as a member of cluster k. 
\\
totals=zeros(1,K);
\\
% I use the logical and sum properties to derive the total number of examples in cluster k:
\\
for k=1:K
\\
totals(k)=sum(k==idx);
\\
end

\\
% I add/combine all of the examples in cluster k :

for i=1:m    \\   %iterate through the number of examples
    for k=1:K \\  %iterate through the number of clusters
        if (idx(i)==k)  \\  % If the index of the ith example equals the kth cluster
            centroids(k,:) = centroids(k,:)+ X(i,:); \\  %Add the example to the centroid matrix
        end\\
    end\\
end\\


% I divide each cluster row by the total number of clusters in that row:
for k=1:K\\
centroids(k,:) = centroids(k,:)./(totals(k));\\
end
\\
\\
The next section uses PCA to reduce/ compress data as well as returning from a reduced represenation to an approximation of the original data set.
\\

\end{document}
